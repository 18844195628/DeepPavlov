{
  "dataset_reader": {
    "name": "basic_lang_model_reader",
    "x": "text",
    "y": "text",
    "data_path": "snips",
    "train": "train_short.csv"
  },
  "dataset_iterator": {
    "name": "basic_classification_iterator",
    "seed": 42,
    "field_to_split": "train",
    "split_fields": [
      "train",
      "valid"
    ],
    "split_proportions": [
      0.9,
      0.1
    ]
  },
  "chainer": {
    "in": [
      "x"
    ],
    "in_y": [
      "x"
    ],
    "pipe": [
      {
        "in": "x",
        "out": "x_prep",
        "id": "my_preprocessor",
        "name": "str_lower"
      },
      {
        "in": "x_prep",
        "out": "x_tok",
        "id": "my_tokenizer",
        "name": "nltk_moses_tokenizer"
      },
      {
        "in": "x_tok",
        "id": "tokens_vocab",
        "name": "simple_vocab",
        "pad_with_zeros": false,
        "special_tokens": [
          "<UNK>",
          "<SOS>",
          "<EOS>"
        ],
        "fit_on": [
          "x_tok"
        ],
        "level": "token",
        "save_path": "seq2seq/snips/tokens.dict",
        "load_path": "seq2seq/snips/tokens.dict",
        "out": "x_tok_ind",
        "min_freq": 2
      },
      {
        "ref": "tokens_vocab",
        "in": "x_tok_ind",
        "out": "x_spec_tokens"
      },
      {
        "in": "x_spec_tokens",
        "out": "x_emb",
        "id": "my_embedder",
        "name": "glove",
        "pad_zero": true,
        "load_path": "embeddings/glove.6B.100d.txt"
      },
      {
        "in": "x_emb",
        "in_y": "x_tok_ind",
        "out": "y_tok_ind",
        "main": true,
        "name": "keras_seq2seq_model",
        "save_path": "seq2seq/snips/lstm_lstm_model_v0",
        "load_path": "seq2seq/snips/lstm_lstm_model_v0",
        "encoder_embedding_size": "#my_embedder.dim",
        "decoder_embedding_size": "#my_embedder.dim",
        "source_vocab_size": "#tokens_vocab.__len__()",
        "target_vocab_size": "#tokens_vocab.__len__()",
        "target_start_of_sequence_index": "#tokens_vocab.__getitem__('<SOS>')",
        "target_end_of_sequence_index": "#tokens_vocab.__getitem__('<EOS>')",
        "source_max_length": 10,
        "target_max_length": 10,
        "decoder_embedder": "#my_embedder",
        "decoder_vocab": "#tokens_vocab",
        "optimizer": "Adam",
        "lear_rate": 0.01,
        "lear_rate_decay": 0.1,
        "loss": "categorical_crossentropy",
        "hidden_size": 128,
        "model_name": "lstm_lstm_model"
      },
      {
        "ref": "tokens_vocab",
        "in": "y_tok_ind",
        "out": "y_spec_tokens"
      },
      {
        "ref": "my_tokenizer",
        "in": "y_spec_tokens",
        "out": "y_text"
      }
    ],
    "out": "y_text"
  },
  "train": {
    "epochs": 100,
    "batch_size": 64,
    "metrics": [
      "bleu",
      "per_token_accuracy"
    ],
    "validation_patience": 5,
    "val_every_n_epochs": 1,
    "log_every_n_epochs": 1,
    "show_examples": false,
    "validate_best": true,
    "test_best": false
  },
  "metadata": {
    "requirements": [
      "../dp_requirements/tf.txt",
      "../dp_requirements/fasttext.txt"
    ],
    "download": [
      "http://files.deeppavlov.ai/datasets/wikitext-2-v1.tar.gz",
      "http://files.deeppavlov.ai/deeppavlov_data/vocabs.tar.gz"
    ]
  }
}
