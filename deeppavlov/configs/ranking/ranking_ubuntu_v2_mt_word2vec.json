{
  "dataset_reader": {
    "name": "ubuntu_v2_mt_reader",
    "data_path": "./ubuntu_v2_data",
    "num_context_turns": 10
  },
  "dataset_iterator": {
    "name": "siamese_iterator",
    "seed": 243
  },
  "chainer": {
    "in": [
      "x"
    ],
    "in_y": [
      "y"
    ],
    "pipe": [
      {
        "name": "split_tokenizer",
        "id": "tok_1"
      },
      {
        "name": "simple_vocab",
        "id": "vocab_1",
        "save_path": "ubuntu_v2_mt_vocabs/int_tok.dict",
        "load_path": "ubuntu_v2_mt_vocabs/int_tok.dict"
      },
      {
        "in": [
          "x"
        ],
        "out": [
          "x_proc_vect_unused"
        ],
        "fit_on": [
          "x"
        ],
        "retrain": false,
        "id": "word2vec_vectorizer",
        "name": "word2vec_vectorizer",
        "save_path": "ubuntu_v2_mt_word2vec/w2v.model",
        "load_path": "ubuntu_v2_mt_word2vec/w2v.model",
        "notes": "We need to train word2vec embeddings before using in emb_mat_assembler"
      },
      {
        "id": "preproc",
        "name": "siamese_preprocessor",
        "save_path": "vocabs/tok.dict",
        "load_path": "vocabs/tok.dict",
        "use_matrix": true,
        "num_ranking_samples": 10,
        "num_context_turns": 10,
        "max_sequence_length": 50,
        "embedding_dim": "#word2vec_vectorizer.dim",
        "fit_on": [
          "x"
        ],
        "in": [
          "x"
        ],
        "out": [
          "x_proc"
        ],
        "tokenizer": {
          "ref": "tok_1",
          "notes": "use defined tokenizer"
        },
        "vocab": {
          "ref": "vocab_1",
          "notes": "use vocab built for tokenized data"
        },
        "embedder": {
          "ref": "word2vec_vectorizer",
          "notes": "use prepared word2vec embeddings"
        },
        "sent_vocab":
        {
          "id": "siam_sent_vocab",
          "name":"simple_vocab",
          "save_path": "ubuntu_v2_vocabs/sent.dict",
          "load_path": "ubuntu_v2_vocabs/sent.dict"
        }
      },
      {
        "id": "embeddings",
        "name": "emb_mat_assembler",
        "embedder": "#word2vec_vectorizer",
        "vocab": "#vocab_1"
      },
      {
        "in": ["x_proc"],
        "in_y": ["y"],
        "out": ["y_predicted"],
        "name": "dam_nn",
        "num_context_turns": "#preproc.num_context_turns",
        "len_vocab": "#vocab_1.len",
        "max_sequence_length": "#preproc.max_sequence_length",
        "embedding_dim": "#word2vec_vectorizer.dim",
        "emb_matrix": "#embeddings.emb_mat",
        "seed": 243,
        "learning_rate": 1e-3,
        "batch_size": 100,
        "save_path": "ubuntu_v2_mt_model/model",
        "load_path": "ubuntu_v2_mt_model/model"
      }

    ],
    "out": [
      "y_predicted"
    ]
  },
  "train": {
    "epochs": 10,
    "batch_size": 100,
    "pytest_max_batches": 2,
    "train_metrics": [],
    "metrics": [
      "r@1",
      "rank_response"
    ],
    "validation_patience": 3,
    "val_every_n_epochs": 1,
    "log_every_n_batches": 1000
  },
  "metadata": {
    "requirements": [
      "../dp_requirements/tf.txt",
      "../dp_requirements/gensim.txt",
      "../dp_requirements/fasttext.txt"
    ],
    "labels": {
      "telegram_utils": "SiameseModel",
      "server_utils": "Ranker"
    },
    "download": [
      {
        "url": "http://lnsigo.mipt.ru/export/datasets/ubuntu_v2_data.tar.gz",
        "subdir": "ubuntu_v2_data"
      },
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin",
        "subdir": "ubuntu_v2_embeddings"
      }
    ]
  }
}