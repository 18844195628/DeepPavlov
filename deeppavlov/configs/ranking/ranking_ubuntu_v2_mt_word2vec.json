{
  "dataset_reader": {
    "name": "ubuntu_v2_reader_mt",
    "data_path": "./ubuntu_v2_data",
    "num_context_turns": 10
  },
  "dataset_iterator": {
    "name": "siamese_iterator",
    "seed": 243
  },
  "chainer": {
    "in": [
      "x"
    ],
    "in_y": [
      "y"
    ],
    "pipe": [
      {
        "name": "twokenize_tokenizer",
        "id": "tok_1"
      },
      {
        "name": "simple_vocab",
        "id": "vocab_1",
        "save_path": "ubuntu_v2_mt_vocabs/int_tok.dict",
        "load_path": "ubuntu_v2_mt_vocabs/int_tok.dict"
      },
      {
        "in": [
          "x"
        ],
        "out": [
          "x_proc_vect_unused"
        ],
        "fit_on": [
          "x"
        ],
        "retrain": false,
        "id": "word2vec_vectorizer",
        "name": "word2vec_vectorizer",
        "save_path": "ubuntu_v2_mt_word2vec/w2v.model",
        "load_path": "ubuntu_v2_mt_word2vec/w2v.model",
        "notes": "We need to train word2vec embeddings before using in emb_mat_assembler"
      },
      {
        "id": "preproc",
        "name": "siamese_preprocessor",
        "save_path": "vocabs/tok.dict",
        "load_path": "vocabs/tok.dict",
        "use_matrix": true,
        "num_ranking_samples": 10,
        "num_context_turns": 10,
        "max_sequence_length": 10,
        "embedding_dim": "#word2vec_vectorizer.dim",
        "fit_on": [
          "x"
        ],
        "in": [
          "x"
        ],
        "out": [
          "x_proc"
        ],
        "tokenizer": {
          "ref": "tok_1",
          "notes": "use 'twokenizer'"
        },
        "vocab": {
          "ref": "vocab_1",
          "notes": "use vocab built for 'twokenized' data"
        },
        "embedder": {
          "ref": "word2vec_vectorizer",
          "notes": "use prepared word2vec embeddings"
        }
      },
      {
        "id": "embeddings",
        "name": "emb_mat_assembler",
        "embedder": "#word2vec_vectorizer",
        "vocab": "#siam_vocab"
      },
      {
        "in": [
          "x_proc"
        ],
        "in_y": [
          "y"
        ],
        "out": [
          "y_predicted"
        ],
        "name": "siamese_model",
        "device_num": 0,
        "train_now": true,
        "network": {
          "name": "bilstm_gru_nn",
          "use_matrix": "#preproc.use_matrix",
          "num_context_turns": "#preproc.num_context_turns",
          "len_vocab": "#siam_vocab.len",
          "max_sequence_length": "#preproc.max_sequence_length",
          "embedding_dim": "#word2vec_vectorizer.dim",
          "emb_matrix": "#embeddings.emb_mat",
          "seed": 243,
          "hidden_dim": 300,
          "learning_rate": 1e-3,
          "triplet_loss": false
        },
        "batch_size": 256,
        "num_context_turns": "#preproc.num_context_turns",
        "save_path": "ubuntu_v2_mt_ranking/model_weights.h5",
        "load_path": "ubuntu_v2_mt_ranking/model_weights.h5"
      }
    ],
    "out": [
      "y_predicted"
    ]
  },
  "train": {
    "epochs": 200,
    "batch_size": 256,
    "pytest_max_batches": 2,
    "train_metrics": [],
    "metrics": [
      "r@1",
      "rank_response"
    ],
    "validation_patience": 10,
    "val_every_n_epochs": 1,
    "log_every_n_batches": 1000
  },
  "metadata": {
    "requirements": [
      "../dp_requirements/tf.txt",
      "../dp_requirements/gensim.txt",
      "../dp_requirements/fasttext.txt"
    ],
    "labels": {
      "telegram_utils": "SiameseModel",
      "server_utils": "Ranker"
    },
    "download": [
      {
        "url": "http://lnsigo.mipt.ru/export/datasets/ubuntu_v2_data.tar.gz",
        "subdir": "ubuntu_v2_data"
      },
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin",
        "subdir": "ubuntu_v2_embeddings"
      }
    ]
  }
}