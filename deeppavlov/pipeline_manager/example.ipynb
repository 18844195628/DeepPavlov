{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Приветствую !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это небольшая инструкция по использованию функционала для автоматического перебора различных пайплайнов в DeepPavlov. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы постоянно пробуете кучу разных экспериментов, используя DeepPavlov. Вам интересно попробовать много всего разного: моделей, ембеддингов, разного препроцессинга. И для того чтобы провести новый эксперимент вам каждый раз треубется залезать в конфиг, убирать что-то из chainer-а, ручками переписывать параметры, потом снова всё это запускать, а вам всё это делать некогда, так как вы очень занятой человек (скорее всего это просто лень), и хочется просто запустить в консоли одну волшебную команду, то вы мой клиент, и эта штука точно облегчит вам в жизнь (на самом деле не точно). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот вам конкретный пример. Решается задача классификации, допустим интентов. У вас есть 10 моделей (которые могут её решать), несколько токенайзеров, опечаточник, лемматизатор, ELMo, fasttext, и много чего ещё. И вы хотите автоматически прогнать кучу экспериментов с разными моделями и компонентами, чтобы в итоге сформулировать некий отчёт, из которого будет видно какие модели лучше показали себя на практике, что круче fasstext или ELMo, даёт ли присутствие лемматизации с опечаточником в пайплайне какой-нибудь буст, т.д. И желательно всё сразу. А вообще неплохо было бы ещё при этом гиперапараметры моделей подобрать.\n",
    "\n",
    "Нормальная такая ситуация. Хочется это дело частично автоматизировать. Собственно это, условный \"pipeline_manager\" (давайте будем называть его так (если есть иные варианты названия, то жду предложений)), как раз и делает. Это специальный класс, который берёт на вход путь к конфиг файлу, и ряд дополнительных параметров, которые задают его режим работы. В конфиг файле задан некий \"шаблон перебора\" пайплайнов, на основании которого специальный генератор внутри класса, комбинируя различные компоненты указанные в шаблоне перебора, выдаёт набор конфигов в стандартном для DeepPavlov-а виде. Дальше каждый такой конфиг запускается, обучается и тестируется при помощи встроенного инструментария библиотеки. По мере обучения и тестирования различных пайплайнов когнфиги пайплайнов и промежуточные результаты логируются в отдельном файлике. По окончании работы алгоритма, в папке Downloads появится новая папка experiments, в которой будут содержатся логи, веса моделей, а также excel файл с отображением всех исполненных пайплайнов с описанием компонент, и достигнутых значений на метриках. \n",
    "\n",
    "Также в конфиге можно задать перебор гиперпараметров как для основной модели, так и для остальных компонент, после чего осуществить \"random\" или \"grid\" поиск в указанных рамках. Как именно это делать будет описано чуть ниже. При поиске оптимальных гиперпараметров, время испольнения алгоритма может существенно увеличится, за этим требуется следить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сам класс располагается по следующему пути\n",
    "from deeppavlov.pipeline_manager.pipeline_manager import PipelineManager\n",
    "# И экземпляр класса создаётся следующим образом\n",
    "manager = PipelineManager(config_path, exp_name, mode, info, root, hyper_search, sample_num, target_metric)\n",
    "\n",
    "# Запускается эксперимент так\n",
    "manager.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config_path - str: Путь к конфиг файлу в котором задан шаблон перебора пайплайнов, параметры обучения, и т.д. это обязательный параметр без значения по дефолту\n",
    "\n",
    "exp_name - str: Имя эксперимента, требуется для формирования логов и отчёта, это обязательный параметр без значения по дефолту\n",
    "\n",
    "mode - str: [train, evaluate] режим работы pipeline manager, может как обучать данные, так и тестить уже обученные модели, train используются по умолчанию\n",
    "\n",
    "root - str: Путь к папке в которой будет формироваться отчёт, и создаться папка experiments, значение './experiments/' используется по умолчанию\n",
    "\n",
    "hyper_search - str: [grid, random] тригер указывающий какой тип поиска, grid используюется по умолчанию\n",
    "\n",
    "sample_num - int: Если hyper_search=random, то sample_num указывает количество сгенерированных примеров. Значение по дефолту 10.\n",
    "\n",
    "target_metric - str: Имя метрики на основании которой будет осуществляться сортировка результатов при формировании отчёта. Значение по дефолту None, в таком случае в качестве целевой метрики берется первая из тех имён что указаны в конфиг файле. Если указанной метрики нет в DeepPavlov, вызовется ошибка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание конфиг файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам требуется явно задать шаблон перебора разных компонент. Как все мы знаем при написании конфига для эксперимента мы в поле \"chainer\" задаём \"pipe\" в виде списка словарей, которые описывают последовательность компонент и их параметров. Вот пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_example = {\"chainer\": {\"in\": [\"x\"], \"in_y\": [\"y\"],\n",
    "                          \"pipe\": [\n",
    "                                    {\"id\": \"classes_vocab\",\n",
    "                                     \"name\": \"default_vocab\",\n",
    "                                     \"fit_on\": [\"y\"],\n",
    "                                     \"level\": \"token\",\n",
    "                                     \"save_path\": \"vocabs/snips_classes.dict\",\n",
    "                                     \"load_path\": \"vocabs/snips_classes.dict\"},\n",
    "                                    {\"id\": \"my_embedder\",\n",
    "                                     \"name\": \"fasttext\",\n",
    "                                     \"save_path\": \"embeddings/dstc2_fastText_model.bin\",\n",
    "                                     \"load_path\": \"embeddings/dstc2_fastText_model.bin\",\n",
    "                                     \"dim\": 100},\n",
    "                                    {\"in\": [\"x\"],\n",
    "                                     \"name\": \"str_lower\",\n",
    "                                     \"out\": [\"x\"]},\n",
    "                                    {\n",
    "                                      \"id\": \"my_tokenizer\",\n",
    "                                      \"name\": \"nltk_tokenizer\",\n",
    "                                      \"tokenizer\": \"wordpunct_tokenize\"\n",
    "                                    },\n",
    "                                    {\n",
    "                                    \"in\": [\"x\"],\n",
    "                                    \"in_y\": [\"y\"],\n",
    "                                    \"out\": [\"y_labels\", \"y_probas_dict\"],\n",
    "                                    \"main\": True,\n",
    "                                    \"scratch_init\": True,\n",
    "                                    \"name\": \"intent_model\",\n",
    "                                    \"save_path\": \"intents/intent_cnn_snips_v4\",\n",
    "                                    \"classes\": \"#classes_vocab.keys()\",\n",
    "                                    \"kernel_sizes_cnn\": [1, 2, 3],\n",
    "                                    \"filters_cnn\": 256,\n",
    "                                    \"confident_threshold\": 0.5,\n",
    "                                    \"optimizer\": \"Adam\",\n",
    "                                    \"lear_rate\": 0.01,\n",
    "                                    \"lear_rate_decay\": 0.1,\n",
    "                                    \"loss\": \"binary_crossentropy\",\n",
    "                                    \"text_size\": 15,\n",
    "                                    \"coef_reg_cnn\": 1e-4,\n",
    "                                    \"coef_reg_den\": 1e-4,\n",
    "                                    \"dropout_rate\": 0.5,\n",
    "                                    \"dense_size\": 100,\n",
    "                                    \"model_name\": \"cnn_model\",\n",
    "                                    \"embedder\": \"#my_embedder\",\n",
    "                                    \"tokenizer\": \"#my_tokenizer\"},\n",
    "                                  ],\n",
    "                          \"out\": [\"y_labels\", \"y_probas_dict\"]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной случае на каждом этапе исполнения пайплайна присутствет лишь одна компонента. В общем-то и перебирать нечего (а ведь хочеться), так что давайте кое что добавим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"chainer\": {\"in\": [\"x\"], \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      [{\"id\": \"classes_vocab\",\n",
    "        \"name\": \"default_vocab\",\n",
    "        \"fit_on\": [\"y\"],\n",
    "        \"level\": \"token\",\n",
    "        \"save_path\": \"vocabs/snips_classes.dict\",\n",
    "        \"load_path\": \"vocabs/snips_classes.dict\"}],\n",
    "      [{\"id\": \"my_embedder\",\n",
    "        \"name\": \"fasttext\",\n",
    "        \"save_path\": \"embeddings/dstc2_fastText_model.bin\",\n",
    "        \"load_path\": \"embeddings/dstc2_fastText_model.bin\",\n",
    "        \"dim\": 100}],\n",
    "      [{\"in\": [\"x\"],\n",
    "        \"name\": \"str_lower\",\n",
    "        \"out\": [\"x\"]},\n",
    "        None],\n",
    "      [{\"id\": \"my_tokenizer\",\n",
    "        \"name\": \"nltk_tokenizer\",\n",
    "        \"tokenizer\": \"wordpunct_tokenize\"},\n",
    "       {\"id\": \"my_tokenizer\",\n",
    "        \"name\": \"lazy_tokenizer\",\n",
    "        \"tokenizer\": \"wordpunct_tokenize\"}],\n",
    "      [{\"in\": [\"x\"], \"in_y\": [\"y\"],\n",
    "        \"out\": [\"y_labels\", \"y_probas_dict\"],\n",
    "        \"main\": True,\n",
    "        \"scratch_init\": True,\n",
    "        \"name\": \"intent_model\",\n",
    "        \"save_path\": \"intents/intent_cnn_snips_v4\",\n",
    "        \"classes\": \"#classes_vocab.keys()\",\n",
    "        \"kernel_sizes_cnn\": [1, 2, 3],\n",
    "        \"filters_cnn\": 256,\n",
    "        \"confident_threshold\": 0.5,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lear_rate\": 0.01,\n",
    "        \"lear_rate_decay\": 0.1,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"text_size\": 15,\n",
    "        \"coef_reg_cnn\": 1e-4,\n",
    "        \"coef_reg_den\": 1e-4,\n",
    "        \"dropout_rate\": 0.5,\n",
    "        \"dense_size\": 100,\n",
    "        \"model_name\": \"cnn_model\",\n",
    "        \"embedder\": \"#my_embedder\",\n",
    "        \"tokenizer\": \"#my_tokenizer\"},\n",
    "       {\"in\": [\"x\"], \"in_y\": [\"y\"],\n",
    "        \"out\": [\"y_labels\", \"y_probas_dict\"],\n",
    "        \"main\": True,\n",
    "        \"scratch_init\": True,\n",
    "        \"name\": \"intent_model\",\n",
    "        \"save_path\": \"intents/intent_cnn_snips_v4\",\n",
    "        \"classes\": \"#classes_vocab.keys()\",\n",
    "        \"units_lstm\": 128,\n",
    "        \"rec_dropout_rate\": 0.5,\n",
    "        \"confident_threshold\": 0.5,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lear_rate\": 0.01,\n",
    "        \"lear_rate_decay\": 0.1,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"text_size\": 15,\n",
    "        \"coef_reg_lstm\": 1e-4,\n",
    "        \"coef_reg_den\": 1e-4,\n",
    "        \"dropout_rate\": 0.5,\n",
    "        \"dense_size\": 100,\n",
    "        \"model_name\": \"bilstm_model\",\n",
    "        \"embedder\": \"#my_embedder\",\n",
    "        \"tokenizer\": \"#my_tokenizer\"}]\n",
    "       ],\n",
    "    \"out\": [\"y_labels\", \"y_probas_dict\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное отличие в том, что здесь каждый элемент списка в поле \"pipe\", сам является списком, даже если он содержит один компонент. Ну и как можно видеть теперь у нас в конфиге два токенайзера (на самом деле они одинаковые, но в DeepPavlov это разные классы), и две модели CNN и bi-LSTM. Также обратите внимание что третий элемент кроме словаря также содержит None. Это значит, что этот элемент может и вовсе отсутствовать в пайплайне, и будут созданы запущены пайплайны не содержащие этого компонента.\n",
    "\n",
    "Вот в общем-то и всё. Для того чтобы задать шаблон перебора вам требуется взять ваш конфиг, который вы уже использовали до этого и дописать в \"pipe\" chainer-a дополнительные компоненты и модели, которые вы хотите попробовать. Главное не забыть что каждый элемент в новом \"pipe\" является отдельным списком. После чего уже можно запустить эксперимент через командную строку, введя:\n",
    "\n",
    "### python -m deeppavlov sort_out  <путь к новому конфиг файлу>  -e  <имя эксперимента>\n",
    "\n",
    "После чего процесс запустится. По окончании в папке Downloads появится папка Experiments, в которой будут сохраняться все ваши данные, отчёты, чекпоинты по отдельным экспериментам рассортированные по датам и именам экспериментов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Если же вы хотите написать какую-то свою функцию с использованием pipeline manager-a, то вот пример его использования напрямую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.pipeline_manager.pipeline_manager import PipelineManager\n",
    "from deeppavlov.core.commands.utils import set_deeppavlov_root, expand_path\n",
    "from deeppavlov.download import deep_download\n",
    "\n",
    "set_deeppavlov_root({})\n",
    "data_path = expand_path('snips')\n",
    "\n",
    "# АХТУНГ!!!! если хотите запустить, то и пути вам конечно же все надо поменять и свой конфиг написать\n",
    "path = '/home/mks/projects/DeepPavlov/deeppavlov/configs/my_configs/intents/intents_snips.json'\n",
    "exp_name = 'test'\n",
    "mode = 'train'\n",
    "root = '/home/mks/projects/DeepPavlov/experiments/'\n",
    "hyper_search = 'grid'\n",
    "sample_num = 10\n",
    "target_metric = 'classification_f1'\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    deep_download(['-c', path])\n",
    "\n",
    "    manager = PipelineManager(config_path=path, exp_name=exp_name, mode=mode, root=root,\n",
    "                              hyper_search=hyper_search, sample_num=sample_num, target_metric=target_metric)\n",
    "    manager.run()\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
