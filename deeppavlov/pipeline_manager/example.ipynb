{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приветствую !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это небольшая инструкция по использованию функционала для автоматического перебора пайплайнов в DeepPavlov. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зачем это нужно ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конкретный пример. Решается задача классификации, допустим интентов. У вас есть 10 моделей, которые могут какой-то результат, несколько токенайзеров, опечаточник, лемматизатор, ELMo, fasttext, и много чего ещё. И по хорошему, вам бы попробовать все модели, желательно ещё и с разными комбинациями векторизации и препроцессинга. После чего сформировать некий отчёт по проведённым экспериментам. Чтобы наглядно увидеть какая модель работает лучше, что круче ELMo или fasttext, и т.д.\n",
    "\n",
    "Представленный ниже функционал позволяет автоматизировать, в некоторой мере, вышеперечисленные задачи, и облегчить вам жизнь (но это не точно)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание основного класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"pipeline_manager\" - это специальный класс, который берёт на вход путь к конфиг файлу, и ряд дополнительных параметров, которые задают его режим работы. В конфиг файле задан некий \"шаблон перебора\" пайплайнов, на основании которого специальный генератор внутри класса, комбинируя различные компоненты указанные в шаблоне перебора, выдаёт набор конфигов в стандартном для DeepPavlov-а виде. Дальше каждый такой конфиг отдельно запускается, обучается и тестируется при помощи функционала библиотеки. По мере обучения и тестирования различных пайплайнов когнфиги пайплайнов и промежуточные результаты логируются в отдельном файлике. По окончании работы алгоритма, в папке Downloads появится новая папка experiments, в которой будут содержатся логи, веса моделей, а также excel файл с отображением всех исполненных пайплайнов с описанием компонент, и достигнутых значений на метриках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сам класс располагается по следующему пути\n",
    "from deeppavlov.pipeline_manager.pipeline_manager import PipelineManager\n",
    "\n",
    "# И экземпляр класса создаётся следующим образом\n",
    "manager = PipelineManager(config_path, exp_name, mode, info, root, hyper_search, sample_num, target_metric)\n",
    "\n",
    "# Запускается эксперимент так\n",
    "manager.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**config_path** - str: Путь к конфиг файлу, в котором задан шаблон перебора пайплайнов, параметры обучения, и т.д. это обязательный параметр без значения по дефолту\n",
    "\n",
    "**exp_name** - str: Имя эксперимента, требуется для формирования логов и отчета, это обязательный параметр без значения по дефолту\n",
    "\n",
    "**mode** - str: [train, evaluate] режим работы pipeline manager, может как обучать данные, так и тестить уже обученные модели, train используется по умолчанию\n",
    "\n",
    "**info** - Dict or None: Просто некая дополнительная информация, которую вы хотите сохранить в логах в виде словаря. Информация может быть любой, этот параметр не влияет на работу pipeline manager. По умолчанию принимает значение None.\n",
    "\n",
    "**root** - str: Путь к папке в которой будет формироваться отчет, и создаться папка experiments, значение './experiments/' используется по умолчанию\n",
    "\n",
    "**hyper_search** - str: [grid, random] триггер указывающий какой тип поиска, grid используется по умолчанию\n",
    "\n",
    "**sample_num** - int: Если hyper_search=random, то sample_num указывает количество сгенерированных примеров. Значение по дефолту 10.\n",
    "\n",
    "**target_metric** - str: Имя метрики на основании которой будет осуществляться сортировка результатов при формировании отчёта. Значение по дефолту None, в таком случае в качестве целевой метрики берется первая из тех имён что указаны в конфиг файле. Если указанной метрики нет в DeepPavlov, вызовется исключение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание конфиг файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конфиг, путь к которому подаётся на вход классу pipeline manager, отличается от \"стандартного\" конфига, который требуется написать для запуска некой модели в DeepPavlov, лишь тем, как в нём описывается содержание поля \"pipe\" в чейнере. Вот краткая версия того как в чейнере задаётся поле \"pipe\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"chainer\": {\"in\": [\"x\"], \"in_y\": [\"y\"],\n",
    "             \"pipe\": [\n",
    "                       {\"id\": \"classes_vocab\",\n",
    "                        ...},\n",
    "                       {\"id\": \"my_embedder\",\n",
    "                        ...},\n",
    "                       {\"in\": [\"x\"],\n",
    "                        \"name\": \"str_lower\",\n",
    "                        \"out\": [\"x\"]},\n",
    "                       {\"id\": \"my_tokenizer\",\n",
    "                         ...},\n",
    "                       {\"in\": [\"x\"], \"in_y\": [\"y\"], \"out\": [\"y_labels\", \"y_probas_dict\"],\n",
    "                        \"main\": True,\n",
    "                        \"name\": \"intent_model\",\n",
    "                        ...},\n",
    "                     ],\n",
    "             \"out\": [\"y_labels\", \"y_probas_dict\"]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно в примере, мы задаём поле \"pipe\" в виде списка словарей, которые явно описывают последовательность компонент и их параметров. В то время как для автоматического запуска множества разных пайплайнов, нам требуется задать шаблон перебора разных компонент. Для этого каждый элемент списка в поле \"pipe\" трансформируется в отдельный список словарей, в котором идёт перечисление компонент с параметрами, которые требуются для перебора. Даже если на некой позиции в пайплайне расположен всего один компонент, то он должен быть обёрнут в список. Вот пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"chainer\": {\"in\": [\"x\"], \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      [{\"id\": \"classes_vocab\",\n",
    "        ...}],\n",
    "      [{\"id\": \"my_embedder\",\n",
    "        ...}],\n",
    "      [{\"name\": \"str_lower\", ...}, None],\n",
    "      [{\"name\": \"nltk_tokenizer\",\n",
    "        ...},\n",
    "       {\"name\": \"lazy_tokenizer\",\n",
    "        ...}],\n",
    "      [{\"name\": \"intent_model\",\n",
    "        \"model_name\": \"cnn_model\",\n",
    "        ...},\n",
    "       {\"name\": \"intent_model\",\n",
    "        \"model_name\": \"bilstm_model\",\n",
    "        ...}]\n",
    "       ],\n",
    "    \"out\": [\"y_labels\", \"y_probas_dict\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть теперь у нас в конфиге два токенайзера, и две модели CNN и bi-LSTM.Также обратите внимание что третий элемент кроме словаря также содержит None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"pipe\": [...\n",
    "         [{\"name\": \"str_lower\", ...}, None],\n",
    "         ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это значит, что этот элемент может и вовсе отсутствовать в пайплайне. В итоге будут созданы пайплайны не содержащие этого компонента. В данном случае несложно посчитать, что в эксперименте будет запущено 8 разных пайплайнов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот в общем-то и всё. Для того чтобы задать шаблон перебора вам требуется взять ваш конфиг, который вы уже использовали до этого и дописать в \"pipe\" chainer-a дополнительные компоненты и модели, которые вы хотите попробовать. Главное не забыть что каждый элемент в новом \"pipe\" является отдельным списком. Потом уже можно запустить эксперимент через командную строку, введя:\n",
    "\n",
    "### python -m deeppavlov sort_out  <путь к новому конфиг файлу>  -e  <имя эксперимента>\n",
    "\n",
    "По окончании в папке downloads появится папка experiments, в которой будут сохраняться все ваши данные, отчёты, чекпоинты по отдельным экспериментам, рассортированные по датам и именам экспериментов.\n",
    "\n",
    "Может возникнуть такая ситуация, что в рамках одного конфига вы не сможете описать все желаемые варианты пайплайнов, из-за несовместимости отдельных компонент. В таком случае вы можете создать два конфига, и поочерёдно запустить их, указав одно и тоже имя эксперимента, в таком случае, все логи и отчёты, автоматически соединяться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также pipeline manager может осуществлять подбор гиперпараметров как основной модели, так и отдельных компонент, если требуется. На данный момент поддерживается \"random\" или \"grid\" поиск. При поиске оптимальных гиперпараметров, количество различных пайплайнов, а следовательно и время испольнения алгоритма, может существенно увеличится, это надо иметь в виду."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для запуска подбора гиперпараметров требуется в конфиге указать для каких именно компонент требуется осуществлять подбор. Это делается за счёт добавления в словарь, описывающий компоненту и ее параметры, пары ключ-значение -  \"search\": True; После чего нужным параметрам сопоставить список со значениями для перебора.\n",
    "\n",
    "**ВАЖНОЕ ЗАМЕЧАНИЕ:**\n",
    "Если в исходном словаре имеются имеются ключи, значениями которых являются списки, то им следует добавить ещё один уровень вложенности. (См. пример ниже)\n",
    "\n",
    "Вот пример словаря по которому можно осуществлять grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"search\": True,\n",
    " \"in\": [[\"x\"]], \"in_y\": [[\"y\"]], \"out\": [[\"y_labels\", \"y_probas_dict\"]],\n",
    " \"main\": True,\n",
    " \"scratch_init\": True,\n",
    " \"name\": \"intent_model\",\n",
    " \"save_path\": \"intents/intent_cnn_snips_v4\",\n",
    " \"classes\": \"#classes_vocab.keys()\",\n",
    " \"kernel_sizes_cnn\": [[1, 2, 3], [1, 3, 6]],\n",
    " \"filters_cnn\": [64, 128, 256],\n",
    " \"confident_threshold\": [0.1, 0.3, 0.5, 0.7],\n",
    " \"optimizer\": \"Adam\",\n",
    " \"lear_rate\": [0.01, 0.001],\n",
    " \"lear_rate_decay\": 0.1,\n",
    " \"loss\": \"binary_crossentropy\",\n",
    " \"text_size\": [15, 20, 25, 40],\n",
    " \"coef_reg_cnn\": 1e-4,\n",
    " \"coef_reg_den\": 1e-4,\n",
    " \"dropout_rate\": 0.5,\n",
    " \"dense_size\": [50, 100, 150, 200],\n",
    " \"model_name\": \"cnn_model\",\n",
    " \"embedder\": \"#my_embedder\",\n",
    " \"tokenizer\": \"#my_tokenizer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь по большому счёту ситуация такая же. Однако если grid search осуществит перебор всех возможных комбинаций параметров, то random search семплирует случайные наборы параметров из указанных в конфиге диапазонов определённое количество раз. За это отвечает параметр sample_num в pipeline manager. Добавление вложенности при наличии в словаре списков в качестве значений, здесь также необходимо.\n",
    "\n",
    "Функционал при Random search несколько больше. Если вы вы параметру присвоите список значений, то при семплирования будет случайно будет выбран один из его элементов. Однако параметру можно также сопоставить и словарь инструкциями:\n",
    "\n",
    "**\"some_parameter\": {\"bool\": True}** - Случайно присвоит True или False\n",
    "\n",
    "**\"some_parameter\": {\"range\": [start, end]}** - Присваивает случайное значение из указанного диапазона\n",
    "\n",
    "**\"some_parameter\": {\"range\": [start, end], \"scale\": \"log\"}** - Присваивает случайное значение из указанного диапазона, но в логарифмическом масштабе.\n",
    "\n",
    "**\"some_parameter\": {\"range\": [start, end], \"discrete\": True}** - Присваивает случайное, и округлённое, значение из указанного диапазона\n",
    "\n",
    "Вот пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"search\": True,\n",
    " \"in\": [[\"x\"]], \"in_y\": [[\"y\"]], \"out\": [[\"y_labels\", \"y_probas_dict\"]],\n",
    " \"main\": True,\n",
    " \"scratch_init\": True,\n",
    " \"name\": \"intent_model\",\n",
    " \"save_path\": \"intents/intent_cnn_snips_v4\",\n",
    " \"classes\": \"#classes_vocab.keys()\",\n",
    " \"kernel_sizes_cnn\": [[1, 2, 3], [1, 3, 6]],\n",
    " \"filters_cnn\": {'range': [64, 512], 'discrete': True},\n",
    " \"confident_threshold\": 0.5,\n",
    " \"optimizer\": \"Adam\",\n",
    " \"lear_rate\": {'range': [0.1, 0.0001], 'scale': 'log'},\n",
    " \"lear_rate_decay\": 0.1,\n",
    " \"loss\": \"binary_crossentropy\",\n",
    " \"text_size\": 15,\n",
    " \"coef_reg_cnn\": 1e-4,\n",
    " \"coef_reg_den\": 1e-4,\n",
    " \"dropout_rate\": 0.5,\n",
    " \"dense_size\": 100,\n",
    " \"model_name\": \"cnn_model\",\n",
    " \"embedder\": \"#my_embedder\",\n",
    " \"tokenizer\": \"#my_tokenizer\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
